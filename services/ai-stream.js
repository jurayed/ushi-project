const { createClient, LiveTranscriptionEvents } = require('@deepgram/sdk');
const { OpenAI } = require('openai');
const { pool } = require('../models/database');

const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

// Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ ÐºÐ»Ð¸ÐµÐ½Ñ‚ OpenAI (Ð´Ð»Ñ TTS, Ð¾Ð½ Ð²ÑÐµÐ³Ð´Ð° Ð½ÑƒÐ¶ÐµÐ½)
const openaiBase = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function getUserName(userId) {
    try {
        const res = await pool.query('SELECT username FROM users WHERE id = $1', [userId]);
        return res.rows[0]?.username || 'User';
    } catch (e) { return 'User'; }
}

async function fetchHistory(userId) {
    try {
        const result = await pool.query(
            `SELECT message_text, is_ai_response FROM messages WHERE user_id = $1 ORDER BY sent_at DESC LIMIT 20`,
            [userId]
        );
        return result.rows.reverse().map(msg => ({
            role: msg.is_ai_response ? 'assistant' : 'user',
            content: msg.message_text
        }));
    } catch (e) { return []; }
}

async function saveMessage(userId, text, isAi) {
    try {
        await pool.query(
            'INSERT INTO messages (user_id, message_text, is_ai_response, ai_psychotype) VALUES ($1, $2, $3, $4)',
            [userId, text, isAi, 'voice-mode']
        );
    } catch (e) {}
}

class AiStreamSession {
    constructor(socket, userId) {
        this.socket = socket;
        this.userId = userId;
        this.dgConnection = null;
        this.isProcessing = false;
        this.sentenceBuffer = ""; 
        this.systemPrompt = "Ð¢Ñ‹ ÑÐ¼Ð¿Ð°Ñ‚Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÐ¾Ð±ÐµÑÐµÐ´Ð½Ð¸Ðº.";
        
        // ðŸ”¥ ÐÐÐ¡Ð¢Ð ÐžÐ™ÐšÐ˜ ÐœÐžÐ”Ð•Ð›Ð˜
        this.provider = 'openai'; 
        this.model = 'gpt-4o';
        
        this.metrics = { stt_start: 0, stt_end: 0, llm_start: 0, llm_first_byte: 0, tts_start: 0, tts_end: 0 };
    }

    start(config = {}) {
        if (config.systemPrompt) this.systemPrompt = config.systemPrompt;
        
        // ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ñ Ñ„Ñ€Ð¾Ð½Ñ‚Ð°
        if (config.provider) this.provider = config.provider;
        if (config.model) this.model = config.model;

        console.log(`ðŸŽ¤ Config: Provider=${this.provider}, Model=${this.model}`);

        this.dgConnection = deepgram.listen.live({
            model: "nova-2", language: "ru", smart_format: true,
            encoding: "linear16", sample_rate: 16000, interim_results: true,
            vad_events: true, endpointing: 300
        });

        this.dgConnection.on(LiveTranscriptionEvents.Open, () => {
            console.log("ðŸŸ¢ STT Stream Started");
            this.metrics.stt_start = Date.now();

            this.dgConnection.on(LiveTranscriptionEvents.Transcript, (data) => {
                const transcript = data.channel.alternatives[0].transcript;
                if (data.is_final && transcript.trim().length > 0) {
                    
                    this.metrics.stt_end = Date.now();
                    const sttTime = this.metrics.stt_end - this.metrics.stt_start;
                    this.sendMetric('stt', sttTime);
                    this.metrics.stt_start = Date.now(); 

                    this.socket.emit('user_transcription', { text: transcript, isFinal: true });
                    this.processLLM(transcript);
                } else {
                    if(transcript.trim()) this.socket.emit('user_transcription', { text: transcript, isFinal: false });
                }
            });
        });
        
        this.dgConnection.on(LiveTranscriptionEvents.Error, (err) => console.error(err));
    }

    handleAudioChunk(chunk) {
        if (this.dgConnection && this.dgConnection.getReadyState() === 1) {
            this.dgConnection.send(chunk);
        }
    }

    sendMetric(type, value) {
        this.socket.emit('latency_metric', { type, value });
    }

    // ðŸ”¥ Ð“Ð•ÐÐ•Ð ÐÐ¦Ð˜Ð¯ ÐšÐ›Ð˜Ð•ÐÐ¢Ð Ð’ Ð—ÐÐ’Ð˜Ð¡Ð˜ÐœÐžÐ¡Ð¢Ð˜ ÐžÐ¢ ÐŸÐ ÐžÐ’ÐÐ™Ð”Ð•Ð Ð
    getLlmClient() {
        if (this.provider === 'deepseek') {
            return new OpenAI({
                apiKey: process.env.DEEPSEEK_API_KEY,
                baseURL: 'https://api.deepseek.com'
            });
        }
        // Fallback for OpenAI or unsupported providers in Live Mode
        return openaiBase;
    }

    async processLLM(text) {
        if (this.isProcessing) return;
        this.isProcessing = true;
        this.metrics.llm_start = Date.now();

        try {
            await saveMessage(this.userId, text, false);
            const history = await fetchHistory(this.userId);
            const username = await getUserName(this.userId);
            
            const enhancedPrompt = `${this.systemPrompt}\n\n[CONTEXT]\nUser Name: ${username}`;

            const messages = [
                { role: "system", content: enhancedPrompt + " ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾, Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½Ð¾." },
                ...history,
                { role: "user", content: text }
            ];

            // Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
            const client = this.getLlmClient();

            const stream = await client.chat.completions.create({
                model: this.model, // Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ!
                messages: messages, 
                stream: true,
            });

            this.sentenceBuffer = "";
            let fullResponse = "";
            let firstByteReceived = false;

            for await (const chunk of stream) {
                const content = chunk.choices[0]?.delta?.content || "";
                if (!content) continue;

                if (!firstByteReceived) {
                    this.metrics.llm_first_byte = Date.now();
                    this.sendMetric('llm', this.metrics.llm_first_byte - this.metrics.llm_start);
                    firstByteReceived = true;
                }

                this.socket.emit('ai_text_chunk', { text: content });
                this.sentenceBuffer += content;
                fullResponse += content;

                if (this.shouldSpeak(content)) {
                    const textToSpeak = this.sentenceBuffer.trim();
                    if (textToSpeak.length > 2) {
                        await this.generateAndSendAudio(textToSpeak);
                        this.sentenceBuffer = "";
                    }
                }
            }

            if (this.sentenceBuffer.trim().length > 0) {
                await this.generateAndSendAudio(this.sentenceBuffer);
            }
            
            await saveMessage(this.userId, fullResponse, true);
            this.socket.emit('ai_response_complete');

        } catch (error) {
            console.error("LLM Error:", error);
            this.socket.emit('ai_text_chunk', { text: ` Error: ${error.message}` });
        } finally {
            this.isProcessing = false;
        }
    }

    shouldSpeak(chunk) { return ['.', '!', '?', '\n'].some(punct => chunk.includes(punct)); }

    async generateAndSendAudio(text) {
        try {
            this.metrics.tts_start = Date.now();
            
            // TTS Ð²ÑÐµÐ³Ð´Ð° Ñ‡ÐµÑ€ÐµÐ· OpenAI (Ð¿Ð¾ÐºÐ° Ñ‡Ñ‚Ð¾)
            const mp3 = await openaiBase.audio.speech.create({
                model: "tts-1", voice: "shimmer", input: text, response_format: "mp3",
            });
            const buffer = Buffer.from(await mp3.arrayBuffer());
            
            this.metrics.tts_end = Date.now();
            this.sendMetric('tts', this.metrics.tts_end - this.metrics.tts_start);

            this.socket.emit('ai_audio_chunk', buffer);
        } catch (e) { console.error("TTS Error:", e); }
    }

    stop() {
        if (this.dgConnection) {
            this.dgConnection.finish();
            this.dgConnection = null;
        }
    }
}

const sessions = new Map();

module.exports = {
    handleStreamConnection: (socket) => {
        socket.on('start_voice_chat', (config) => {
            const session = new AiStreamSession(socket, socket.userId);
            sessions.set(socket.id, session);
            session.start(config); 
            console.log(`ðŸŽ¤ Session started for ${socket.id}`);
        });

        socket.on('audio_stream_data', (chunk) => {
            const session = sessions.get(socket.id);
            if (session) session.handleAudioChunk(chunk);
        });

        socket.on('stop_voice_chat', () => {
            const session = sessions.get(socket.id);
            if (session) session.stop();
            sessions.delete(socket.id);
        });

        socket.on('disconnect', () => {
            const session = sessions.get(socket.id);
            if (session) session.stop();
            sessions.delete(socket.id);
        });
    }
};
