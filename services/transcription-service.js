// services/transcription-service.js
// –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Node 18+ (–≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π fetch –∏ FormData)

async function transcribeAudio(audioBuffer, filename = 'voice.webm') {
    if (!process.env.OPENAI_API_KEY) {
        throw new Error('OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ');
    }

    try {
        console.log(`üéôÔ∏è –ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (${filename}, ${audioBuffer.length} –±–∞–π—Ç)...`);

        const formData = new FormData();
        // –í–∞–∂–Ω–æ: —Å–æ–∑–¥–∞–µ–º Blob —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ç–∏–ø–æ–º
        const blob = new Blob([audioBuffer], { type: 'audio/webm' });
        formData.append('file', blob, filename);
        formData.append('model', 'whisper-1');

        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
                // Content-Type —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±—Ä–∞—É–∑–µ—Ä–æ–º/node fetch
            },
            body: formData
        });

        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            console.error('‚ùå –û—à–∏–±–∫–∞ OpenAI Whisper:', JSON.stringify(errorData, null, 2));
            throw new Error(`Whisper API Error: ${errorData.error?.message || response.statusText}`);
        }

        const result = await response.json();
        console.log('‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞:', result.text.substring(0, 50) + '...');
        
        return {
            text: result.text,
            language: result.language || 'unknown'
        };

    } catch (error) {
        console.error('‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:', error.message);
        throw error;
    }
}

module.exports = { transcribeAudio };
